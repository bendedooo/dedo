{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec93a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from scipy import stats\n",
    "\n",
    "# Some useful utilities\n",
    "from mcmc_utils_and_plot import scatter_matrix, build_cov_mat, lognormpdf, plot_bivariate_gauss, eval_func_on_grid, sub_sample_data\n",
    "\n",
    "def compose(*functions):\n",
    "    \"Compose a list of functions\"\n",
    "    return functools.reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odeFuncI(t,x):\n",
    "    N = 1000\n",
    "    S = x[0]\n",
    "    I = x[1]\n",
    "    R = x[2]\n",
    "    beta = 0.2\n",
    "    r = 0.6\n",
    "    delta = 0.15\n",
    "    # theta = np.array([beta, r, delta]) # true parameter settings\n",
    "    y0 = delta*N - delta*S - beta*I*S  # del S\n",
    "    y1 = beta*I*S - (r+delta)*I        # del I\n",
    "    y2 = r*I - delta*R                 # del R\n",
    "    return y0,y1,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solverFuncI():\n",
    "    timeVec = np.linspace(0,6,61)\n",
    "    S_0 = 900\n",
    "    I_0 = 100\n",
    "    R_0 = 0\n",
    "    x_0 = np.array([S_0, I_0, R_0])\n",
    "    soln = scipy.integrate.solve_ivp(odeFuncI,[0,6],x_0,t_eval=timeVec,method='RK45')\n",
    "    return soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solnI = solverFuncI()\n",
    "data1 = np.zeros(61)\n",
    "stdNoise = 50 \n",
    "for ii in range (len(data1)):\n",
    "    data1[ii]=solnI.y[1,ii]+stdNoise*np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf941b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num='Identifiable Version',figsize=(10,8))\n",
    "plt.plot(solnI.t,solnI.y[0,:],'y',linewidth=4,label='Susceptible')\n",
    "plt.plot(solnI.t,solnI.y[1,:],'m',linewidth=4,label='Infected')\n",
    "plt.plot(solnI.t,solnI.y[2,:],'c',linewidth=4,label='Recovered')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num='Data',figsize=(10,8))\n",
    "plt.plot(solnI.t,solnI.y[1,:],'m',linewidth=4,label='Infected')\n",
    "plt.scatter(solnI.t,data1, c='r', marker='X',s=33,label='Data')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odeFuncU(t,x):\n",
    "    N = 1000\n",
    "    S = x[0]\n",
    "    I = x[1]\n",
    "    R = x[2]\n",
    "    gamma = 0.2\n",
    "    kappa = 0.1\n",
    "    r = 0.6\n",
    "    delta = 0.15\n",
    "    # theta = np.array([gamma, kappa, r, delta]) # true parameter settings\n",
    "    y0 = delta*N - delta*S - gamma*kappa*I*S  # del S\n",
    "    y1 = gamma*kappa*I*S - (r+delta)*I        # del I\n",
    "    y2 = r*I - delta*R                 # del R\n",
    "    return y0,y1,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solverFuncU():\n",
    "    timeVec = np.linspace(0,6,61)\n",
    "    S_0 = 900\n",
    "    I_0 = 100\n",
    "    R_0 = 0\n",
    "    x_0 = np.array([S_0, I_0, R_0])\n",
    "    soln = scipy.integrate.solve_ivp(odeFuncU,[0,6],x_0,t_eval=timeVec,method='RK45')\n",
    "    return soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "solnU = solverFuncU()\n",
    "data2 = np.zeros([61,1])\n",
    "stdNoise = 50\n",
    "for ii in range (0,len(data2)):\n",
    "    data2[ii]=solnU.y[1,ii]+stdNoise*np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num='Undentifiable Version',figsize=(10,8))\n",
    "plt.plot(solnU.t,solnU.y[0,:],'y',linewidth=4,label='Susceptible')\n",
    "plt.plot(solnU.t,solnU.y[1,:],'m',linewidth=4,label='Infected')\n",
    "plt.plot(solnU.t,solnU.y[2,:],'c',linewidth=4,label='Recovered')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f972c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num='Data',figsize=(10,8))\n",
    "plt.plot(solnU.t,solnU.y[1,:],'m',linewidth=4,label='Infected')\n",
    "plt.scatter(solnU.t,data2, c='r', marker='X',s=33,label='Data')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    beta = 0.2\n",
    "    r = 0.6\n",
    "    delta = 0.15\n",
    "    theta_t = np.array([beta, r, delta]) # true parameter settings\n",
    "    #theta = np.random.randn(3)\n",
    "    print(theta_t)\n",
    "    gamma = 0.2\n",
    "    kappa = 0.1\n",
    "    theta_tU = np.array([gamma, kappa,r, delta]) # true parameter settings\n",
    "    print(theta_tU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihoodI(thetain,data):\n",
    "    timeVec = np.linspace(0,6,61)\n",
    "    beta = thetain[0]\n",
    "    r = thetain[1]\n",
    "    delta = thetain[2]\n",
    "    S_0 = 900\n",
    "    I_0 = 100\n",
    "    R_0 = 0\n",
    "    N = 1000\n",
    "    x_0 = np.array([S_0, I_0, R_0])\n",
    "    soln = scipy.integrate.solve_ivp(odeFuncI, [0,6], y0=x_0, method='RK45', t_eval=timeVec)\n",
    "\n",
    "#     print(np.round(np.sum(soln.y,axis=0)))\n",
    "#     if np.any(np.round(np.sum(soln.y,axis=0))!=N):\n",
    "#         return -np.inf\n",
    "    if thetain[0] >= 0 and thetain[1] >= 0 and thetain[2] >= 0:\n",
    "        std = 50\n",
    "#         pre_exp_term = 1/(np.sqrt(2*np.pi)*std)\n",
    "#         exp_term = -0.5*np.square((data.T-soln.y[1])/std)\n",
    "#         f = np.log(pre_exp_term)+exp_term\n",
    "        f = np.zeros(len(soln.y[1,:]))\n",
    "        for ii in range(len(soln.y[1,:])):\n",
    "             f[ii] = np.log(scipy.stats.norm.pdf(data[ii],soln.y[1,ii], std))\n",
    "        f_theta0 = (np.log(scipy.stats.norm.pdf(thetain[0],0,1)))\n",
    "        f_theta1 = (np.log(scipy.stats.norm.pdf(thetain[1],0,1)))\n",
    "        f_theta2 = (np.log(scipy.stats.norm.pdf(thetain[2],0,1)))\n",
    "        f_theta = np.sum(np.array([f_theta0, f_theta1, f_theta2]))\n",
    "        out=np.sum(f) + f_theta\n",
    "        \n",
    "    else:\n",
    "        return -np.inf\n",
    "        \n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logpostI = lambda params: log_likelihoodI(params, data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiVarLogPDF(x,y,cov):\n",
    "    x_mu = x-y\n",
    "    logpdf = np.log((1/(np.sqrt((2*np.pi)**2*np.linalg.det(cov))))*np.exp(-0.5*np.dot((x_mu).T,np.dot(np.linalg.inv(cov),x_mu))))\n",
    "    return logpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayedRejectionAdaptiveMetropolis:\n",
    "    \n",
    "    def __init__(self, logpdf, cov, t0=100, freq=10, sd=None, max_samples=10000, eps=1e-7): \n",
    "        \"\"\"The class constructor, parameters are documented below\"\"\"\n",
    "        self.logpdf = logpdf # callable (param) -> logpdf defining the logpdf\n",
    "        self.cov = cov # initial covariance\n",
    "        self.cov_chol = np.linalg.cholesky(cov) # sqrt of the covariance\n",
    "        self.dim = cov.shape[0] # number of parameters\n",
    "        self.t0 = t0 # time to start adapting\n",
    "        self.freq = freq # frequency of covariance updates (should be an integer > 0)\n",
    "        if sd == None:\n",
    "            self.sd = (2.4**2) / self.dim\n",
    "        else:\n",
    "            self.sd = sd # scale for the covariance                    \n",
    "        self.max_samples = max_samples # maximum number of samples\n",
    "        self.eps = eps # nugget for ensuring positive definite\n",
    "        self.num_samples = 0 # number of samples generated\n",
    "        self.samples = np.zeros((max_samples, self.dim)) # store the samples\n",
    "        self.logpdf_vals = np.zeros((max_samples))\n",
    "        \n",
    "        self.sample_mean = self.samples[0,:]\n",
    "        \n",
    "    def sample(self, initial_sample, num_samples):\n",
    "    \n",
    "        assert num_samples <= self.max_samples, \"Requesting more samples than space is allocated for\"\n",
    "        \n",
    "        self.samples[0, :] = initial_sample\n",
    "        self.logpdf_vals[0] = self.logpdf(initial_sample)\n",
    "        \n",
    "        accept = 1\n",
    "        for ii in range(1, num_samples):\n",
    "            \n",
    "            # propose\n",
    "            y = self.samples[ii-1, :] + np.dot(self.cov_chol, np.random.randn(self.dim))\n",
    "            y_logpdf = self.logpdf(y)\n",
    "            \n",
    "            # compute accept-reject probability, using the fact that we have a symmetric proposal\n",
    "            a = np.exp(y_logpdf - self.logpdf_vals[ii-1])\n",
    "            a = min(a, 1)\n",
    "    \n",
    "            u = np.random.rand()\n",
    "        \n",
    "            if u < a: #accept\n",
    "                self.samples[ii, :] = y\n",
    "                self.logpdf_vals[ii] = y_logpdf\n",
    "                accept += 1\n",
    "            else:\n",
    "                # propose\n",
    "                self.num_samples += 1\n",
    "                chollev2 = np.linalg.cholesky(0.5*self.cov) # sqrt of the covariance\n",
    "                y2 = self.samples[ii-1, :] + np.dot(chollev2, np.random.randn(self.dim))\n",
    "                y_logpdf2 = self.logpdf(y2)\n",
    "                \n",
    "                a1y2y1 = np.exp(y_logpdf-y_logpdf2)\n",
    "                a1xy1 = np.exp(y_logpdf - self.logpdf_vals[ii-1])\n",
    "                \n",
    "                q1 = multiVarLogPDF(y,y2,self.cov)\n",
    "                q2 = multiVarLogPDF(y,self.samples[ii-1, :],self.cov)\n",
    "                \n",
    "                a2 = np.exp((y_logpdf2+np.log(1-a1y2y1))-(self.logpdf_vals[ii-1]+np.log(1-a1xy1)) + q1 - q2)\n",
    "                a2 = min(a2,1)\n",
    "                \n",
    "                u2 = np.random.rand()\n",
    "\n",
    "                if u2 < a2: # accept\n",
    "                    self.samples[ii, :] = y2\n",
    "                    self.logpdf_vals[ii] = y_logpdf2\n",
    "                    accept += 1\n",
    "                else:\n",
    "                    self.samples[ii, :] = self.samples[ii-1, :]\n",
    "                    self.logpdf_vals[ii] = self.logpdf_vals[ii-1]\n",
    "                    \n",
    "            self.num_samples += 1\n",
    "             \n",
    "            \n",
    "            # adapt covariance if its time\n",
    "            if ii > self.t0 and ii % self.freq == 0:\n",
    "                sampleMeanNew = (1/(ii+1))*self.samples[ii, :]+(ii/(ii+1))*self.sample_mean\n",
    "                covUpdate     = self.eps*np.eye(self.dim) + ii*np.dot(self.sample_mean,self.sample_mean) - \\\n",
    "                                (ii+1)*np.dot(sampleMeanNew,sampleMeanNew) + \\\n",
    "                                 np.dot(self.samples[ii, :],self.samples[ii, :])\n",
    "                self.cov = (ii-1)*self.cov/ii + self.sd*covUpdate/ii \n",
    "                self.cov_chol = np.linalg.cholesky(self.cov)\n",
    "                self.sample_mean = sampleMeanNew           \n",
    "            if ii % 1000 == 0:\n",
    "                print(f\"Finished sample {ii}, acceptance ratio = {accept / self.num_samples}\")\n",
    "                \n",
    "        return self.samples, accept / float (self.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_approx(initial_guess, logpost):\n",
    "    \"\"\"Perform the laplace approximation, \n",
    "        returning the MAP point and an approximation of the covariance\n",
    "        \n",
    "    Inputs\n",
    "    ------\n",
    "    initial_guess: (nparam, ) array of initial parameters\n",
    "    logpost: function (param) -> log posterior\n",
    "    \n",
    "    Ouputs\n",
    "    ------\n",
    "    map_point: (nparam, ) MAP of the posterior\n",
    "    cov_approx: (nparam, nparam), covariance matrix for Gaussian fit at MAP\n",
    "    \"\"\"\n",
    "    def neg_post(x):\n",
    "        \"\"\"Negative posteror because optimizer is a minimizer\"\"\"\n",
    "        return -logpost(x)\n",
    "    \n",
    "    # Gradient free method to obtain optimum\n",
    "    res = scipy.optimize.minimize(neg_post, initial_guess, method='Nelder-Mead') \n",
    "    # Gradient method which also approximates the inverse of the hessian\n",
    "    res = scipy.optimize.minimize(neg_post, res.x)\n",
    "\n",
    "    map_point = res.x\n",
    "    cov_approx = res.hess_inv\n",
    "    return map_point, cov_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "dim=3\n",
    "guess = np.random.randn((dim)) # random guess\n",
    "map_point, cov_laplace = laplace_approx(guess, logpostI)\n",
    "initial_sample = map_point\n",
    "covin = cov_laplace\n",
    "print(cov_laplace)\n",
    "print(map_point)\n",
    "\n",
    "data = data1\n",
    "dram = DelayedRejectionAdaptiveMetropolis(logpostI, covin, freq=5, t0=300, sd = None, eps = 1e-7, max_samples=num_samples)\n",
    "\n",
    "samples, ar = dram.sample(initial_sample,num_samples)\n",
    "print(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc43755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_sample_data(samples, frac_burn=0.2, frac_use=0.7):\n",
    "    \"\"\"Subsample data by burning off the front fraction and using another fraction\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    samples: (N, d) array of samples\n",
    "    frac_burn: fraction < 1, percentage of samples from the front to ignore\n",
    "    frac_use: percentage of samples to use after burning, uniformly spaced\n",
    "    \"\"\"\n",
    "    nsamples = samples.shape[0]\n",
    "    inds = np.arange(nsamples, dtype=np.int)\n",
    "    start = int(frac_burn * nsamples)\n",
    "    inds = inds[start:]\n",
    "    nsamples = nsamples - start\n",
    "    step = int(nsamples / (nsamples * frac_use))\n",
    "    inds2 = np.arange(0, nsamples, step)\n",
    "    inds = inds[inds2]\n",
    "    return samples[inds, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb839fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sub_sample_data(samples, frac_burn=0.2, frac_use=0.7)\n",
    "fig, axs, gs = scatter_matrix([samples_sub], hist_plot=False, gamma=0.2, labels=[r'$\\theta_1$', r'$\\theta_2$', r'$\\theta_3$'])\n",
    "fig.set_size_inches(10,10)\n",
    "plt.subplots_adjust(left=0.01, right=0.99, wspace=0.2, hspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(samples, maxlag=100, step=1):\n",
    "    \"\"\"Compute the correlation of a set of samples\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    samples: (N, d)\n",
    "    maxlag: maximum distance to compute the correlation for\n",
    "    step: step between distances from 0 to maxlag for which to compute teh correlations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the shapes\n",
    "    ndim = samples.shape[1]\n",
    "    nsamples = samples.shape[0]    \n",
    "    \n",
    "    # Compute the mean\n",
    "    mean = np.mean(samples, axis=0)\n",
    "    \n",
    "    # Compute the denominator, which is variance\n",
    "    denominator = np.zeros((ndim))\n",
    "    for ii in range(nsamples):\n",
    "        denominator = denominator + (samples[ii, :] - mean)**2\n",
    "    \n",
    "    lags = np.arange(0, maxlag, step)\n",
    "    autos = np.zeros((len(lags), ndim))\n",
    "    for zz, lag in enumerate(lags):\n",
    "        autos[zz, :] = np.zeros((ndim))\n",
    "        # compute the covariance between all samples *lag apart*\n",
    "        for ii in range(nsamples - lag):\n",
    "            autos[zz,:] = autos[zz, :] + (samples[ii,:]-mean)*(samples[ii + lag,:] -mean)\n",
    "        autos[zz, :] = autos[zz, :]/denominator\n",
    "    return lags, autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlag=500\n",
    "step=1\n",
    "lags, autolag = autocorrelation(samples, maxlag=maxlag,step=step)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(lags, autolag[:, 0],'-o')\n",
    "axs[0].set_xlabel('lag')\n",
    "axs[0].set_ylabel('autocorrelation dimension 1')\n",
    "axs[1].plot(lags, autolag[:, 1],'-o')\n",
    "axs[1].set_xlabel('lag')\n",
    "axs[1].set_ylabel('autocorrelation dimension 2')\n",
    "axs[2].plot(lags, autolag[:, 2],'-o')\n",
    "axs[2].set_xlabel('lag')\n",
    "axs[2].set_ylabel('autocorrelation dimension 3')\n",
    "plt.show()\n",
    "\n",
    "IAC1 = 1+2*np.sum(autolag[:,0])\n",
    "print(IAC1)\n",
    "IAC2 = 1+2*np.sum(autolag[:,1])\n",
    "print(IAC2)\n",
    "IAC2 = 1+2*np.sum(autolag[:,2])\n",
    "print(IAC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb66b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(10,5))\n",
    "axs[0].plot(samples[:, 0], '-k')\n",
    "axs[0].set_ylabel(r'$x_1$', fontsize=14)\n",
    "axs[1].plot(samples[:, 1], '-k')\n",
    "axs[1].set_ylabel(r'$x_2$', fontsize=14)\n",
    "axs[1].set_xlabel('Sample Number', fontsize=14)\n",
    "axs[2].plot(samples[:, 2], '-k')\n",
    "axs[2].set_ylabel(r'$x_2$', fontsize=14)\n",
    "axs[2].set_xlabel('Sample Number', fontsize=14)\n",
    "#axs[1].set_xlim([40000, 50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihoodU(thetain,data):\n",
    "    timeVec = np.linspace(0,6,61)\n",
    "    gamma = thetain[0]\n",
    "    kappa = thetain[1]\n",
    "    r = thetain[2]\n",
    "    delta = thetain[3]\n",
    "    S_0 = 900\n",
    "    I_0 = 100\n",
    "    R_0 = 0\n",
    "    N = 1000\n",
    "    x_0 = np.array([S_0, I_0, R_0])\n",
    "    soln = scipy.integrate.solve_ivp(odeFuncU, [0,6], y0=x_0, method='RK45', t_eval=timeVec)\n",
    "\n",
    "#     print(np.round(np.sum(soln.y,axis=0)))\n",
    "#     if np.any(np.round(np.sum(soln.y,axis=0))!=N):\n",
    "#         return -np.inf\n",
    "    if thetain[0] >= 0 and thetain[1] >= 0 and thetain[2] >= 0 and thetain[3] >= 0:\n",
    "        std = 50\n",
    "#         pre_exp_term = 1/(np.sqrt(2*np.pi)*std)\n",
    "#         exp_term = -0.5*np.square((data.T-soln.y[1])/std)\n",
    "#         f = np.log(pre_exp_term)+exp_term\n",
    "        f = np.zeros(len(soln.y[1,:]))\n",
    "        for ii in range(len(soln.y[1,:])):\n",
    "             f[ii] = np.log(scipy.stats.norm.pdf(data[ii], soln.y[1,ii],std))\n",
    "        f_theta0 = (np.log(scipy.stats.norm.pdf(thetain[0],0,1)))\n",
    "        f_theta1 = (np.log(scipy.stats.norm.pdf(thetain[1],0,1)))\n",
    "        f_theta2 = (np.log(scipy.stats.norm.pdf(thetain[2],0,1)))\n",
    "        f_theta3 = (np.log(scipy.stats.norm.pdf(thetain[3],0,1)))\n",
    "        f_theta = np.sum(np.array([f_theta0, f_theta1, f_theta2, f_theta3]))\n",
    "        out=np.sum(f) + f_theta\n",
    "        \n",
    "    else:\n",
    "        return -np.inf\n",
    "        \n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logpostU = lambda params: log_likelihoodU(params, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4385a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "dim=4\n",
    "guess = np.random.randn((dim)) # random guess\n",
    "map_point, cov_laplace = laplace_approx(guess, logpostU)\n",
    "initial_sample = map_point\n",
    "covin = cov_laplace\n",
    "print(cov_laplace)\n",
    "print(map_point)\n",
    "\n",
    "dram = DelayedRejectionAdaptiveMetropolis(logpostU, covin, freq=5, t0=300, sd = None, eps = 1e-7, max_samples=num_samples)\n",
    "\n",
    "\n",
    "samples, ar = dram.sample(theta_tU,num_samples)\n",
    "print(samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14280815",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sub_sample_data(samples, frac_burn=0.2, frac_use=0.7)\n",
    "fig, axs, gs = scatter_matrix([samples_sub], hist_plot=False, gamma=0.2)\n",
    "fig.set_size_inches(10,10)\n",
    "plt.subplots_adjust(left=0.01, right=0.99, wspace=0.2, hspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlag=500\n",
    "step=1\n",
    "lags, autolag = autocorrelation(samples, maxlag=maxlag,step=step)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(lags, autolag[:, 0],'-o')\n",
    "axs[0].set_xlabel('lag')\n",
    "axs[0].set_ylabel('autocorrelation dimension 1')\n",
    "axs[1].plot(lags, autolag[:, 1],'-o')\n",
    "axs[1].set_xlabel('lag')\n",
    "axs[1].set_ylabel('autocorrelation dimension 2')\n",
    "axs[2].plot(lags, autolag[:, 2],'-o')\n",
    "axs[2].set_xlabel('lag')\n",
    "axs[2].set_ylabel('autocorrelation dimension 3')\n",
    "axs[3].plot(lags, autolag[:, 3],'-o')\n",
    "axs[3].set_xlabel('lag')\n",
    "axs[3].set_ylabel('autocorrelation dimension 4')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "IAC1 = 1+2*np.sum(autolag[:,0])\n",
    "print(IAC1)\n",
    "IAC2 = 1+2*np.sum(autolag[:,1])\n",
    "print(IAC2)\n",
    "IAC2 = 1+2*np.sum(autolag[:,2])\n",
    "print(IAC2)\n",
    "IAC3 = 1+2*np.sum(autolag[:,3])\n",
    "print(IAC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(10,10))\n",
    "axs[0].plot(samples[:, 0], '-k')\n",
    "axs[0].set_ylabel(r'$x_1$', fontsize=14)\n",
    "axs[1].plot(samples[:, 1], '-k')\n",
    "axs[1].set_ylabel(r'$x_2$', fontsize=14)\n",
    "axs[1].set_xlabel('Sample Number', fontsize=14)\n",
    "axs[2].plot(samples[:, 2], '-k')\n",
    "axs[2].set_ylabel(r'$x_2$', fontsize=14)\n",
    "axs[2].set_xlabel('Sample Number', fontsize=14)\n",
    "axs[3].plot(samples[:, 3], '-k')\n",
    "axs[3].set_ylabel(r'$x_2$', fontsize=14)\n",
    "axs[3].set_xlabel('Sample Number', fontsize=14)\n",
    "#axs[1].set_xlim([40000, 50000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
